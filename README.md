# ML_EmotionRecognitionFromSpeech
This project focuses on recognizing human emotions from speech audio using deep learning and speech signal processing. By analyzing audio features such as MFCCs (Mel-Frequency Cepstral Coefficients), the model can classify emotions like happy, angry, sad, neutral, and more.
